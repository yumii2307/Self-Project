{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from urllib.parse import quote\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def siksin(place):\n",
    "    base_url = 'https://www.siksinhot.com/search'\n",
    "    url = f'{base_url}?keywords={quote(place)}'\n",
    "    result = requests.get(url)\n",
    "    soup = BeautifulSoup(result.text, 'html.parser')\n",
    "    lis = soup.select('.localFood_list > li')\n",
    "    line = []\n",
    "    for li in lis:\n",
    "        img = li.find('img')['src']\n",
    "        href = li.select_one('figure').find('a')['href']\n",
    "        title = li.select_one('.textBox > h2').get_text()\n",
    "        score = li.select_one('.textBox > .score').get_text()\n",
    "        atags = li.select('.cate > a')\n",
    "        location = atags[0].get_text()\n",
    "        menu = atags[1].get_text()\n",
    "        line.append({'img': img, 'title': title, 'score': score, 'location': location, 'menu': menu, 'href': href})\n",
    "    \n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lyrics(artist, title):\n",
    "    base_url = 'https://search.naver.com/search.naver?where=nexearch&sm=top_hty&fbm=0&ie=utf8&query='\n",
    "    url = f'{base_url}{quote(artist+title)}+%EA%B0%80%EC%82%AC'\n",
    "    result = requests.get(url)\n",
    "    soup = BeautifulSoup(result.text, 'html.parser')\n",
    "    lyr = soup.select_one('.lyrics_txt._lyrics_txt').get_text().strip()\n",
    "\n",
    "    return lyr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import joblib\n",
    "new_cvect = joblib.load('model/imdb_cvect_2.pkl')\n",
    "new_lrc = joblib.load('model/imdb_lrc2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'긍정'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = lyrics('에스파', 'life too short')\n",
    "text = re.sub('[^A-Za-z]', ' ', text)\n",
    "review_cv = new_cvect.transform([text])\n",
    "'긍정' if new_lrc.predict(review_cv)[0] == 1 else '부정'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 1 1 6 1 1 4 9 2 1 6 1 1 1 1 3 1 1 6 3 6 4 2 3 1 1 3 1 2 1 2 2 1 3 1 1\n",
      " 2 2 3 3 2 3 1 7 1 1 2 2 1 6 1 1 6 1 1 1 2 1 1 1 2 1 3 1 1 1 3 1 1 1]\n",
      "{'discussiontalking': 6, 'nothingyou': 33, 'say': 44, 'faceyou': 10, 'think': 56, 'words': 70, 'gospelbut': 15, 'troublei': 58, 'ain': 0, 'got': 16, 'time': 57, 'wasteyou': 64, 'need': 31, 'lifecause': 23, 'life': 22, 'shortyou': 48, 'bored': 1, 'mindyou': 29, 'really': 38, 'nonsensesomewhere': 32, 'elsecause': 9, 've': 61, 'realizei': 37, 'doing': 7, 'regardlessand': 40, 'don': 8, 'carewhat': 4, 'itand': 21, 'matterif': 27, 'like': 24, 'noti': 34, 'having': 19, 'fun': 11, 'sowhy': 50, 'stopdoing': 53, 'regardlessno': 42, 'imma': 20, 'waythat': 67, 'wanti': 63, 'stopsome': 55, 'people': 35, 'meanall': 28, 'phone': 36, 'screenwhen': 45, 'tryna': 59, 'live': 25, 'liveswhy': 26, 'gotta': 17, 'viciousbe': 62, 'business': 2, 'stead': 52, 'getting': 12, 'mineyou': 30, 'regardlessdoing': 41, 'regardlesswhy': 43, 'stopoh': 54, 'won': 69, 'turn': 60, 'glitter': 13, 'goldso': 14, 'whyare': 68, 'wasting': 65, 'somebetter': 49, 'seeds': 46, 'sowthey': 51, 'grow': 18, 'day': 5, 'buteither': 3, 'wayi': 66, 'regardless': 39, 'short': 47}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cvect = CountVectorizer(stop_words='english')\n",
    "a = cvect.fit_transform([text]).toarray()[0]\n",
    "print(a)\n",
    "print(cvect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(a)):\n",
    "    i == cvect.vocabulary_.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
